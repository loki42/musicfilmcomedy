ab -n 1000 -c 10 http://localhost:8080/
Server Software:        CherryPy/3.2.2
Server Hostname:        localhost
Server Port:            8080

Document Path:          /
Document Length:        4580 bytes

Concurrency Level:      10
Time taken for tests:   6.499 seconds
Complete requests:      1000
Failed requests:        0
Write errors:           0
Total transferred:      4721000 bytes
HTML transferred:       4580000 bytes
Requests per second:    153.87 [#/sec] (mean)
Time per request:       64.991 [ms] (mean)
Time per request:       6.499 [ms] (mean, across all concurrent requests)
Transfer rate:          709.38 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.0      0       0
Processing:    17   65  16.2     64     127
Waiting:       16   64  16.2     64     126
Total:         17   65  16.2     64     127

Percentage of the requests served within a certain time (ms)
  50%     64
  66%     71
  75%     75
  80%     78
  90%     86
  95%     92
  98%    100
  99%    102
 100%    127 (longest request)

## with varnish
ab -n 10000 -c 10 http://localhost/
Server Software:        CherryPy/3.2.2
Server Hostname:        localhost
Server Port:            80

Document Path:          /
Document Length:        4580 bytes

Concurrency Level:      10
Time taken for tests:   0.933 seconds
Complete requests:      10000
Failed requests:        0
Write errors:           0
Total transferred:      48190000 bytes
HTML transferred:       45800000 bytes
Requests per second:    10715.12 [#/sec] (mean)
Time per request:       0.933 [ms] (mean)
Time per request:       0.093 [ms] (mean, across all concurrent requests)
Transfer rate:          50425.92 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.1      0       4
Processing:     0    1   3.4      1      86
Waiting:        0    1   3.3      0      85
Total:          0    1   3.4      1      86

Percentage of the requests served within a certain time (ms)
  50%      1
  66%      1
  75%      1
  80%      1
  90%      1
  95%      1
  98%      1
  99%      2
 100%     86 (longest request)

------------ running under uwsgi

This is ApacheBench, Version 2.3 <$Revision: 655654 $>
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking localhost (be patient)
Completed 100 requests
Completed 200 requests
Completed 300 requests
Completed 400 requests
Completed 500 requests
Completed 600 requests
Completed 700 requests
Completed 800 requests
Completed 900 requests
Completed 1000 requests
Finished 1000 requests


Server Software:        CherryPy/3.2.2
Server Hostname:        localhost
Server Port:            8080

Document Path:          /
Document Length:        4578 bytes

Concurrency Level:      10
Time taken for tests:   1.055 seconds
Complete requests:      1000
Failed requests:        0
Write errors:           0
Total transferred:      4719000 bytes
HTML transferred:       4578000 bytes
Requests per second:    948.24 [#/sec] (mean)
Time per request:       10.546 [ms] (mean)
Time per request:       1.055 [ms] (mean, across all concurrent requests)
Transfer rate:          4369.86 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.0      0       0
Processing:     6   10   2.6     10      28
Waiting:        6   10   2.6     10      28
Total:          6   10   2.6     10      28

Percentage of the requests served within a certain time (ms)
  50%     10
  66%     11
  75%     11
  80%     12
  90%     13
  95%     14
  98%     19
  99%     22
 100%     28 (longest request)


hints:

* Now talking on #uwsgi
* Topic for #uwsgi is: uWSGI 1.1-snapshot2 is available for testing http://lists.unbit.it/pipermail/uwsgi/2012-February/003607.html
* Topic for #uwsgi set by unbit!~unbit@93-58-162-185.ip159.fastwebnet.it at Sat Feb 18 19:49:57 2012
<lfactor> Hey guys, i'm just trying out uwsgi and i'm having problems with pscyopg2 (postgresql) I suspect in my user of the connection pool. I'm wondering if other people are using ThreadedConnectionPool without problems or if i'm doing something crazy
<lfactor> the app is a cherrypy app, which i'm just running with uwsgi --http-socket 127.0.0.1:8080 --master --processes 4 --module musicfilmcomedy
<lfactor> the error from postgresql: WARNING:  there is already a transaction in progress
<lfactor> so i'm assuming that 2 threads are grabbing the same connection, before the first one gets to commit. i haven't got this problem running it under cherrypy. 
<unbit> add --lazy
<lfactor> unbit: Thanks, does that impact performance? Should i modify the app instead? 
<unbit> not but it could take more memory
<unbit> as the app is loaded one time per worker
<unbit> the best approach woud be reopening the connection to postgres
<unbit> after each fork()
<unbit> using the post_fork_hook
<lfactor> ahh ok, so in effect currently i'll end up with multiple different connection pools to postgres? 
<unbit> yes
<lfactor> and instead each fork should get/put conn? 
<unbit> exactly
<unbit> one ThreadedConnectionPool per worker
<unbit> map your threadpool creation function to uwsgi.post_fork_hook
<unbit> and it will be called after each fork()
<lfactor> ahh, i suspect i'm confused how this is working then, so a single worker is equivalent to the cherrypy server process, but each process is multithreaded ?
<lfactor> sorry if this is an obvious/stupid question
<lfactor> each worker is multithreaded i mean. 
<unbit> a worker is a process
<unbit> a core is a thread in that process
<unbit> by default you start with a core per process
<unbit> to add more cores add --threads <n>
<unbit> but for each worker
<unbit> you need a differenr thread pool
<lfactor> ahh ok
<lfactor> unbit: thanks for the help. Just benchmarked it in comparison with straight cherrypy and even with lazy it seems to do well :) connection with varnish via the documented method is straight forward as well. :)
<unbit> if you need to gain some memory you can look at ksm
<unbit> (linux-only)
<unbit> on some scenario it helps a lot
<unbit> buf if memory is not a problem for you go with --lazy without problems
<lfactor> the thread pool doesn't use that much memory, and i don't have many other globals at the moment. I'll check out ksm though
<lfactor> ahh, just read about ksm, looks like good stuff, thanks for the pointer










################ new test ################ 








Wed Apr 11 16:59:36 EST 2012

###

with redis beaker sessions 

###
ab -n 1000 -c 10 -C beaker.session.id=8105fbece85a40a4a6b001cb7ea53ead -C musicfilmcomedy=3e6126854d7e4368b7d0c4f8fb75a2c4 http://localhost:8080/en/schedule/Coachella_Weekend_1?uid=5&day=2012-04-13 http://www.musicfilmcomedy.com/en/schedule/Coachella_Weekend_1?uid=5&day=2012-04-13
This is ApacheBench, Version 2.3 <$Revision: 655654 $>
Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/
Licensed to The Apache Software Foundation, http://www.apache.org/

Benchmarking localhost (be patient)
Completed 100 requests
Completed 200 requests
Completed 300 requests
Completed 400 requests
Completed 500 requests
Completed 600 requests
Completed 700 requests
Completed 800 requests
Completed 900 requests
Completed 1000 requests
Finished 1000 requests


Server Software:        CherryPy/3.2.2
Server Hostname:        localhost
Server Port:            8080

Document Path:          /
Document Length:        7470 bytes

Concurrency Level:      10
Time taken for tests:   12.554 seconds
Complete requests:      1000
Failed requests:        0
Write errors:           0
Total transferred:      7682000 bytes
HTML transferred:       7470000 bytes
Requests per second:    79.66 [#/sec] (mean)
Time per request:       125.539 [ms] (mean)
Time per request:       12.554 [ms] (mean, across all concurrent requests)
Transfer rate:          597.58 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.0      0       0
Processing:    51  125  30.2    123     314
Waiting:       51  123  29.7    121     314
Total:         51  125  30.2    123     314

Percentage of the requests served within a certain time (ms)
  50%    123
  66%    136
  75%    145
  80%    149
  90%    163
  95%    177
  98%    194
  99%    201
 100%    314 (longest request)

##########


before retools.





#############

Document Path:          /en/schedule/Coachella_Weekend_1?uid=5&day=2012-04-13
Document Length:        54326 bytes

Concurrency Level:      10
Time taken for tests:   19.463 seconds
Complete requests:      1000
Failed requests:        0
Write errors:           0
Total transferred:      54539000 bytes
HTML transferred:       54326000 bytes
Requests per second:    51.38 [#/sec] (mean)
Time per request:       194.634 [ms] (mean)
Time per request:       19.463 [ms] (mean, across all concurrent requests)
Transfer rate:          2736.46 [Kbytes/sec] received


##############

with retools, behind varnish...


##############

Document Path:          /en/schedule/Coachella_Weekend_1?uid=5&day=2012-04-13
Document Length:        54326 bytes


Concurrency Level:      10
Time taken for tests:   13.697 seconds
Complete requests:      1000
Failed requests:        18
   (Connect: 0, Receive: 0, Length: 18, Exceptions: 0)
Write errors:           0
Non-2xx responses:      18
Total transferred:      53651918 bytes
HTML transferred:       53350746 bytes
Requests per second:    73.01 [#/sec] (mean)
Time per request:       136.975 [ms] (mean)
Time per request:       13.697 [ms] (mean, across all concurrent requests)
Transfer rate:          3825.12 [Kbytes/sec] received

#############

retools direct

##############

Document Path:          /en/schedule/Coachella_Weekend_1?uid=5&day=2012-04-13
Document Length:        54326 bytes

Concurrency Level:      10
Time taken for tests:   14.244 seconds
Complete requests:      1000
Failed requests:        0
Write errors:           0
Total transferred:      54539000 bytes
HTML transferred:       54326000 bytes
Requests per second:    70.20 [#/sec] (mean)
Time per request:       142.444 [ms] (mean)
Time per request:       14.244 [ms] (mean, across all concurrent requests)
Transfer rate:          3739.07 [Kbytes/sec] received

/usr/local/bin/uwsgi --http-socket 127.0.0.1:8080 --master --lazy --processes 4 --module musicfilmcomedy

